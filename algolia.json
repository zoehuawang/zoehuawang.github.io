[
  {
    "objectID": "5409dd738c1d0bf9a5b7aebc6f41dc8189ac9a29",
    "permalink": "/post/mfa%E5%8F%8C%E5%9B%A0%E5%AD%90%E8%AE%A4%E8%AF%81%E6%9C%8D%E5%8A%A1%E7%AB%AF/",
    "title": "MFA双因子认证服务端","content": " 通过FreeRadius+GoogleAuthenticator实现动态口令认证 # 配置文件解释： # /etc/freeradius/radiusd.conf 主配置控制全局行为 # /etc/freeradius/clients.conf 管理客户端网络设备信任关系 # /etc/pam.d/radiusd 配置文件决定具体认证方式（密码/OTP等） # /etc/freeradius/users 定义用户账号和密钥 # /etc/freeradius/sites-enable/default 站点定义认证流程 # /etc/freeradius/mods-enable/dual_factor 自定义的模块，是实现系统账号认证的关键桥梁 # /etc/freeradius/dual_auth.sh 自定义认证的脚本 # 进容器执行操作，编辑配置添加允许连接的客户端： vim /etc/freeradius/clients.conf # 进容器执行操作，添加用户单独的TOTP-secret： google-authenticator -t -d -f -r 3 -R 30 -w 3 -s /etc/freeradius/google_authenticator/wangzhenhua75 # 进容器执行操作，编辑配置添加用户： vim /etc/freeradius/users # 启动 docker run -d --restart always --network host --name freeradius-server ccr.ccs.tencentyun.com/zoehuawang/freeradius-server:v1.1 radiusd -X # 进容器执行测试连接命令： radtest wangzhenhua75 \u0026#34;welljoint449286\u0026#34; 192.168.7.51 1812 \u0026#34;Aa123456\u0026#34; Dockerfile镜像构建过程 FROM freeradius/freeradius-server RUN rm -f /etc/apt/sources.list RUN echo \u0026#34;deb http://mirrors.aliyun.com/ubuntu/ jammy main restricted universe multiverse\u0026#34; \u0026gt; /etc/apt/sources.list RUN echo \u0026#34;deb-src http://mirrors.aliyun.com/ubuntu/ jammy main restricted universe multiverse\u0026#34; \u0026gt;\u0026gt; /etc/apt/ sources.list RUN echo \u0026#34;deb http://mirrors.aliyun.com/ubuntu/ jammy-security main restricted universe multiverse\u0026#34; \u0026gt;\u0026gt; /etc/apt/sources.list RUN echo \u0026#34;deb-src http://mirrors.aliyun.com/ubuntu/ jammy-security main restricted universe multiverse\u0026#34; \u0026gt;\u0026gt; /etc/apt/sources.list RUN echo \u0026#34;deb http://mirrors.aliyun.com/ubuntu/ jammy-updates main restricted universe multiverse\u0026#34; \u0026gt;\u0026gt; /etc/apt/sources.list RUN echo \u0026#34;deb-src http://mirrors.aliyun.com/ubuntu/ jammy-updates main restricted universe multiverse\u0026#34; \u0026gt;\u0026gt; /etc/apt/sources.list RUN echo \u0026#34;deb http://mirrors.aliyun.com/ubuntu/ jammy-proposed main restricted universe multiverse\u0026#34; \u0026gt;\u0026gt; /etc/apt/sources.list RUN echo \u0026#34;deb-src http://mirrors.aliyun.com/ubuntu/ jammy-proposed main restricted universe multiverse\u0026#34; \u0026gt;\u0026gt; /etc/apt/sources.list RUN echo \u0026#34;deb http://mirrors.aliyun.com/ubuntu/ jammy-backports main restricted universe multiverse\u0026#34; \u0026gt;\u0026gt; /etc/apt/sources.list RUN echo \u0026#34;deb-src http://mirrors.aliyun.com/ubuntu/ jammy-backports main restricted universe multiverse\u0026#34; \u0026gt;\u0026gt; /etc/apt/sources.list RUN apt-get update \u0026amp;\u0026amp; apt-get install -y oathtool libpam-google-authenticator tzdata \u0026amp;\u0026amp; apt-get clean -y \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* RUN ln -fs /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \u0026amp;\u0026amp; echo \u0026#34;Asia/Shanghai\u0026#34; \u0026gt; /etc/timezone RUN mkdir /etc/freeradius/google_authenticator RUN rm -f /etc/freeradius/mods-enabled/pam \u0026amp;\u0026amp; ln -s /etc/freeradius/mods-available/dual_factor /etc/freeradius/mods-enabled/ COPY wangzhenhua75 /etc/freeradius/google_authenticator/ COPY radiusd.conf /etc/freeradius/ COPY clients.conf /etc/freeradius/ COPY radiusd /etc/pam.d/ COPY authorize /etc/freeradius/mods-config/files/ COPY default /etc/freeradius/sites-available/ COPY dual_factor /etc/freeradius/mods-available/ COPY dual_auth.sh /etc/freeradius/ ","date": "2025-07-02 10:31:47",
    "updated": "2025-07-02 10:31:47"
  }, 
  {
    "objectID": "b411ad2803402d53d7d6967e58cdeb24f85eba60",
    "permalink": "/post/istio%E4%B9%8B%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83/",
    "title": "Istio之灰度发布","content": " 离线安装 下载连接： https://github.com/istio/istio/releases/download/1.25.2/istio-1.25.2-linux-amd64.tar.gz tar -zxf istio-1.25.2-linux-amd64.tar.gz \u0026amp;\u0026amp; cd istio-1.25.2 cp bin/istioctl /usr/local/bin/ # 生成 Istio 的安装清单文件 istioctl manifest generate --set profile=minimal \\ --set values.meshConfig.enableAutoMtls=false \\ --set components.pilot.k8s.env[0].name=\u0026#34;PILOT_HTTP10\u0026#34; \\ --set components.pilot.k8s.env[0].value=\u0026#34;支持http1.0\u0026#34; \\ \u0026gt; istio-minimal.yaml sed -i \u0026#39;s/支持http1.0/\u0026#34;1\u0026#34;/g\u0026#39; istio-minimal.yaml # 手动下载镜像推送到本私有镜像仓库 grep \u0026#34;image: \u0026#34; istio-minimal.yaml # 修改镜像仓库地址 sed -i \u0026#34;s/docker.io/wellregistry:5000/g\u0026#34; istio-minimal.yaml # 启动istiod kubectl create ns istio-system kubectl apply -f istio-minimal.yaml # 给命名空间添加标签，指示 Istio 在部署应用的时候，自动注入 Envoy Sidecar 代理 kubectl label namespace default istio-injection=enabled # 在yaml文件的spec.template.metadata.lables下添加标签，开启或关闭注入Sidecar sidecar.istio.io/inject: \u0026#34;true\u0026#34; # istio默认配置大概支持1000个svc、2000个sidecar、70000个request请求 卸载 istioctl x uninstall --purge 流量控制 通过VirtualService与DestinationRule根据权重控制流量比例。请求到达服务网格，VirtualService 根据 hosts 和路由规则（如路径、Header）匹配请求将流量指向 DestinationRule 中定义的子集（subset），DestinationRule 根据子集的标签（如 version: product）选择具体的 Pod DestinationRule中的spec.subets.labels对应Deployment中的metadata.labels\napiVersion: v1 kind: Service metadata: name: tmc namespace: cloud2 labels: name: tmc spec: type: NodePort ports: - name: tcp-tmc # 名称包含tcp才能与vs的路由类型匹配 protocol: TCP port: 8080 nodePort: 32004 selector: app: tmc --- apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: namespace: cloud2 name: tmc spec: hosts: - tmc # 目标服务名称 tcp: # 路由类型 - match: - port: 8080 route: # 定义 tcp 路由 - destination: host: tmc # 目标服务名称 subset: prod # 在DestinationRule中定义的子集 weight: 50 - destination: host: tmc # 目标服务名称 subset: gray # 在DestinationRule中定义的子集 weight: 50 --- apiVersion: networking.istio.io/v1alpha3 kind: DestinationRule metadata: namespace: cloud2 name: tmc spec: host: tmc # 目标服务名称 subsets: - name: prod # 子集名称 labels: version: prod # 按标签选择Pod - name: gray # 子集名称 labels: version: gray # 按标签选择Pod deployment示例：\napiVersion: apps/v1 kind: Deployment metadata: namespace: cloud2 name: tmc labels: app: tmc version: prod spec: replicas: 1 selector: matchLabels: app: tmc version: prod template: metadata: labels: app: tmc version: prod sidecar.istio.io/inject: \u0026#34;true\u0026#34; spec: containers: ... ","date": "2025-04-28 10:53:10",
    "updated": "2025-04-28 10:53:10"
  }, 
  {
    "objectID": "cdd8ee5f6d3f7d3a8f5aa5f1a9097ef26e100501",
    "permalink": "/post/%E8%BD%BB%E9%87%8F%E7%BA%A7sip%E5%B7%A5%E5%85%B7sipsak/",
    "title": "轻量级sip工具sipsak","content": "github地址：https://github.com/nils-ohlmeier/sipsak\n编译安装 tar -zxf sipsak-0.9.8.1.tar.gz cd sipsak-0.9.8.1 ./configure make \u0026amp; make install 一、常用方法 #模拟发送option探测 sipsak -H 本地ip -l 本地端口 -s sip:192.168.7.55:18627 -v #模拟发送invite请求，-f从文件加载sip消息，用 ! 分割文件中的变量和值 sipsak -f invite.txt -g \u0026#39;!CALLEE!被叫号码!CALL_ID!\u0026#39;$(uuidgen)\u0026#39;!CALLER!主叫号码!SIP_PORT!本地信令端口!MEDIA_PORT!本地媒体端口!\u0026#39; -H 192.168.7.51 -l 本地信令端口 -s sip:192.168.7.55:18627 -v #文件invite.txt内容模版如下: INVITE sip:$CALLEE$@192.168.7.55:18627 SIP/2.0 Call-ID: $CALL_ID$ From: \u0026#34;$CALLER$\u0026#34;\u0026lt;sip:$CALLER$@192.168.7.51;transport=udp;user=phone\u0026gt; To: \u0026#34;$CALLEE$\u0026#34;\u0026lt;sip:$CALLEE$@192.168.7.51;transport=udp;user=phone\u0026gt; CSeq: 1 INVITE Contact: \u0026lt;sip:192.168.7.51:$SIP_PORT$\u0026gt; Max-Forwards: 10 Content-Length: 154 Content-Type: application/sdp v=0 o=alice 123456 789 IN IP4 192.168.7.51 s=SBC call c=IN IP4 192.168.7.51 t=0 0 m=audio $MEDIA_PORT$ RTP/AVP 0 a=rtpmap:8 PCMA/8000 a=rtpmap:0 PCMU/8000 其中，$CALLEE$为被叫号码、$CALLER$为主叫号码、$CALL_ID$为会话标识\n$SIP_PORT$为本地信令端口、$MEDIA_PORT$ 为本地媒体端口\n注意：Content-Length的值为body的字符长度，计算方法如下：\nsdp=\u0026#34;v=0 o=alice 123456 789 IN IP4 192.168.7.51 s=SBC call c=IN IP4 192.168.7.51 t=0 0 m=audio 18628 RTP/AVP 0 a=rtpmap:8 PCMA/8000 a=rtpmap:0 PCMU/8000\u0026#34; echo \u0026#34;$sdp\u0026#34; | awk \u0026#39;{ bytes += length($0) + 2 } END { print bytes }\u0026#39; 二、sipsak模拟压测脚本 #!/bin/bah while true;do #暂停3～10秒 sleep $(shuf -i 3-10 -n 1) initPort=$(shuf -i 40000-60000 -n 1) #发起10个invite请求 for ((i = 0; i \u0026lt; 10; i++)); do sPt=$((initPort + i * 2)) mPt=$((sPt + 1)) sipsak -f invite.txt -g \u0026#39;!CALLEE!567831!CALL_ID!\u0026#39;$(uuidgen)\u0026#39;!CALLER!+8617621!SIP_PORT!\u0026#39;$sPt\u0026#39;!MEDIA_PORT!\u0026#39;$mPt\u0026#39;!\u0026#39; -H 172.23.33.3 -l $sPt -s sip:172.23.33.8:18627 -v done done ","date": "2025-02-02 10:57:18",
    "updated": "2025-02-02 10:57:18"
  }, 
  {
    "objectID": "a88fa1e6bfbd8e1e995322e4c97f606a803c93f0",
    "permalink": "/post/docker%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2jumpserver/",
    "title": "Docker快速部署jumpserver","content": "# https://github.com/jumpserver/Dockerfile # https://hub.docker.com/r/jumpserver/jms_all # - SECRET_KEY = xxxxx # 自行生成随机的字符串, 不要包含特殊字符串, 长度推荐大于等于 50 # - BOOTSTRAP_TOKEN = xxxxx # 自行生成随机的字符串, 不要包含特殊字符串, 长度推荐大于等于 24 # - LOG_LEVEL = ERROR # 日志等级, 测试环境推荐设置为 DEBUG # - DB_ENGINE = mysql # 使用 MySQL 数据库 # - DB_HOST = mysql_host # MySQL 数据库 IP 地址 # - DB_PORT = 3306 # MySQL 数据库 端口 # - DB_USER = xxx # MySQL 数据库认证用户 # - DB_PASSWORD = xxxx # MySQL 数据库认证密码 # - DB_NAME = jumpserver # JumpServer 使用的数据库名称 # - REDIS_HOST = redis_host # 使用 Redis 缓存 # - REDIS_PORT = 6379 # Redis 服务器 IP 地址 # - REDIS_PASSWORD = xxxx # Redis 认证密码 # - VOLUME /opt/data/jumpserver # Core 持久化目录, 存储录像日志 # - VOLUME /opt/koko/data # Koko 持久化目录 # - VOLUME /opt/lion/data # Lion 持久化目录 # - VOLUME /opt/kael/data # Kael 持久化目录 # - VOLUME /opt/chen/data # Chen 持久化目录 # - VOLUME /var/log/nginx # Nginx 日志持久化目录 MARIADB_PASSWORD=\u0026#34;nu4x599Wq7u0Bn8EABh3J55G\u0026#34; REDIS_PASSWORD=\u0026#34;8URXPL2x3HZMi7xoGTd55Upj\u0026#34; SECRET_KEY=\u0026#34;B3f2w8P2PfxIAS7s4URrD9YmSbtqX4vXdPUL555kL9XPUOWrmy\u0026#34; BOOTSTRAP_TOKEN=\u0026#34;7Q11Vz6R2J5BLAdO\u0026#34; NET_NAME=\u0026#34;jms_net\u0026#34; DBIMAGE=\u0026#34;ccr.ccs.tencentyun.com/myjumpserver/mariadb:10.6\u0026#34; REDISIMAGE=\u0026#34;ccr.ccs.tencentyun.com/myjumpserver/redis:6.2.7\u0026#34; JMSIMAGE=\u0026#34;ccr.ccs.tencentyun.com/myjumpserver/jms_all:v4.6.0\u0026#34; DBPATH=\u0026#34;/opt/jumpserver/jmsMariadb\u0026#34; DATAPATH=\u0026#34;/opt/jumpserver/jmsData\u0026#34; URL_IP=\u0026#34;172.23.33.3\u0026#34; URL_PORT=\u0026#34;8050\u0026#34; docker network create -d bridge --subnet=192.168.65.0/24 $(NET_NAME) || true jms_mariadb: -docker rm -f jms_mariadb; docker run -d -m 384M --network $(NET_NAME) \\ --name jms_mariadb --restart always \\ -e TZ=Asia/Shanghai \\ -e MARIADB_ROOT_PASSWORD=$(MARIADB_PASSWORD) \\ -e MARIADB_USER=jumpserver \\ -e MARIADB_PASSWORD=$(MARIADB_PASSWORD) \\ -e MARIADB_DATABASE=jumpserver \\ -v $(DBPATH):/var/lib/mysql \\ $(DBIMAGE) jms_redis: -docker rm -f jms_redis; docker run -d -m 64M --network $(NET_NAME) \\ --name jms_redis --restart always \\ -e TZ=Asia/Shanghai \\ $(REDISIMAGE) \\ redis-server --requirepass $(REDIS_PASSWORD) --loglevel warning --maxmemory-policy allkeys-lru jms_all: -docker rm -f jms_all; -docker run -d -m 3G --name jms_all --restart always --network $(NET_NAME) \\ -p $(URL_PORT):80 \\ -p 2222:2222 \\ -e TZ=Asia/Shanghai \\ -e DOMAINS=$(URL_IP):$(URL_PORT) \\ -e SECRET_KEY=$(SECRET_KEY) \\ -e BOOTSTRAP_TOKEN=$(BOOTSTRAP_TOKEN) \\ -e LOG_LEVEL=ERROR \\ -e DB_ENGINE=mysql \\ -e DB_HOST=jms_mariadb \\ -e DB_PORT=3306 \\ -e DB_USER=jumpserver \\ -e DB_PASSWORD=$(MARIADB_PASSWORD) \\ -e DB_NAME=jumpserver \\ -e REDIS_HOST=jms_redis \\ -e REDIS_PORT=6379 \\ -e REDIS_PASSWORD=$(REDIS_PASSWORD) \\ --privileged=true \\ -v $(DATAPATH):/opt/data/jumpserver \\ $(JMSIMAGE) jms_restart: -make jms_mariadb; -make jms_redis; -make jms_all ","date": "2025-01-23 10:56:08",
    "updated": "2025-01-23 10:56:08"
  }, 
  {
    "objectID": "00d05394ecee6bc9781502963d9ae381d8df4318",
    "permalink": "/post/kubernetes%E4%B9%8Belk%E9%9B%86%E7%BE%A4/",
    "title": "Kubernetes之ELK集群","content": " 一、elasticsearch集群(3节点) es宿主机配置 vim /etc/sysctl.conf vm.max_map_count=262144 sysctl -p mkdir /mnt/es_data \u0026amp;amp;\u0026amp;amp; chmod 777 /mnt/es_data 创建pv-sc-es.yaml文件 apiVersion: v1 kind: PersistentVolume metadata: name: elasticsearch-pv1 spec: capacity: storage: 10Gi accessModes: - ReadWriteOnce volumeMode: Filesystem persistentVolumeReclaimPolicy: Delete storageClassName: elasticsearch-storage local: path: /mnt/es_data nodeAffinity: required: nodeSelectorTerms: - matchExpressions: - key: es operator: In values: - pv1 --- apiVersion: v1 kind: PersistentVolume metadata: name: elasticsearch-pv2 spec: capacity: storage: 10Gi accessModes: - ReadWriteOnce volumeMode: Filesystem persistentVolumeReclaimPolicy: Delete storageClassName: elasticsearch-storage local: path: /mnt/es_data nodeAffinity: required: nodeSelectorTerms: - matchExpressions: - key: es operator: In values: - pv2 --- apiVersion: v1 kind: PersistentVolume metadata: name: elasticsearch-pv3 spec: capacity: storage: 10Gi accessModes: - …","date": "2024-12-16 11:03:17",
    "updated": "2024-12-16 11:03:17"
  }, 
  {
    "objectID": "62e6aa07472a49393371466a89a91158a3ae97ee",
    "permalink": "/post/%E8%85%BE%E8%AE%AF%E4%BA%91docker%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/",
    "title": "腾讯云docker镜像仓库","content": "#登陆： # docker login --username=4*******6@qq.com registry.cn-hangzhou.aliyuncs.com #阿里云 docker login --username=100004240476 ccr.ccs.tencentyun.com 密码:wzh4*******6 #mysql镜像 #-e MYSQL_ROOT_PASSWORD=Aa123456 -v /home/test/conf:/etc/mysql/mysql.conf.d -v /home/mysql01/data:/var/lib/mysql docker pull ccr.ccs.tencentyun.com/zoehuawang/mysql:5.7 #-e MYSQL_ROOT_PASSWORD=Aa123456 -v /home/mysql/conf:/etc/mysql/conf.d -v /home/mysql/data:/var/lib/mysql -v /home/mysql/log:/var/lib/mysqllog docker pull ccr.ccs.tencentyun.com/zoehuawang/mysql:8.0.30 #redis镜像 docker run -d ccr.ccs.tencentyun.com/myjumpserver/redis:6.2.7 redis-server --requirepass $(REDIS_PASSWORD) --loglevel warning --maxmemory-policy allkeys-lru #proxysql镜像 docker pull ccr.ccs.tencentyun.com/zoehuawang/proxysql:2.5.1 #linux系统镜像，已启动sshd服务 docker run -d --privileged --name centos7.9 ccr.ccs.tencentyun.com/zoehuawang/centos:7.9 /usr/sbin/init docker run -d --privileged --name centos7.9 ccr.ccs.tencentyun.com/zoehuawang/centos:7.9-mac /usr/sbin/init docker run -d --privileged --name centos8.4 ccr.ccs.tencentyun.com/zoehuawang/centos:8.4 /usr/sbin/init docker run -d --privileged --name rockylinux9.3 ccr.ccs.tencentyun.com/zoehuawang/rockylinux:9.3 /usr/sbin/init docker run -d --name ubuntu ccr.ccs.tencentyun.com/zoehuawang/ubuntu:22.04.2 /lib/systemd/systemd docker run -d --privileged --name kylinv10 ccr.ccs.tencentyun.com/zoehuawang/kylin:v10-sp3-amd64 /usr/sbin/init docker run -d --privileged --name kylinv10 ccr.ccs.tencentyun.com/zoehuawang/kylin:v10-sp3-arm64 /usr/sbin/init #python3.7镜像 docker pull ccr.ccs.tencentyun.com/zoehuawang/python:3.7 #最小化镜像 docker pull ccr.ccs.tencentyun.com/zoehuawang/python:3.7_all #基于centos镜像 docker pull ccr.ccs.tencentyun.com/zoehuawang/python:3.7-ffmpeg6.0 #python3和ffmpeg镜像 #ubuntu带桌面的镜像,浏览器访问 https://ip 登陆 docker run -d --name ubuntu --shm-size=512m -p 443:6901 -e VNC_US=vncuser -e VNC_PW=password -u root --restart always -v $(pwd)/data:/home/kasm-user ccr.ccs.tencentyun.com/zoehuawang/ubuntu:22.04-desktop #playwright镜像 docker pull ccr.ccs.tencentyun.com/zoehuawang/ubuntu:22.04.2-playwright #freeswitch1.10.6镜像 docker pull ccr.ccs.tencentyun.com/zoehuawang/freeswitch:1.10.6 #k8s集群部署etcd镜像 docker pull ccr.ccs.tencentyun.com/zoehuawang/etcd:v3.5.7 docker pull ccr.ccs.tencentyun.com/zoehuawang/etcd:v3.5.12 # 自建邮件服务器镜像，https://poste.io/doc/ docker run -d --net=host --restart always -e TZ=Asia/Shanghai -e HTTP_PORT=8020 -e \u0026#34;DISABLE_CLAMAV=TRUE\u0026#34; -e \u0026#34;DISABLE_RSPAMD=FALSE\u0026#34; -e \u0026#34;DISABLE_ROUNDCUBE=FALSE\u0026#34; -v /opt/posteMail:/data --name \u0026#34;postemail\u0026#34; -h \u0026#34;mail.example.com\u0026#34; -t ccr.ccs.tencentyun.com/zoehuawang/poste.io:2.5.6 # 含rtmp、ffmpeg的nginx流媒体镜像------------------------------ docker pull ccr.ccs.tencentyun.com/zoehuawang/nginx-rtmp # rtmp配置文件如： rtmp { server { listen 1935; application live { live on; # 生成mp3文件 exec_push ffmpeg -i rtmp://127.0.0.1:1935/live/$name -fflags +genpts -c:a libmp3lame -ar 8000 -b:a 24k -ac 1 -write_xing 0 -f mp3 -flush_packets 1 -y /tmp/$name.mp3; # 生成wav文件 #exec_push ffmpeg -i rtmp://127.0.0.1:1935/live/$name -c:a pcm_s16le -ar 8000 -ab 24k -ac 2 -f wav -y /tmp/$name.wav; } } } # 含rtmp、ffmpeg的nginx流媒体镜像------------------------------ 容器版centos7报错：Failed to get D-Bus connection: Operation not permitted 。解决方法 mv /usr/bin/systemctl /usr/bin/systemctl.old 下载下面的文件替换掉 /usr/bin/systemctl\nsystemctl\nmv systemctl.txt /usr/bin/systemctl chmod +x /usr/bin/systemctl ","date": "2023-06-27 11:25:53",
    "updated": "2023-06-27 11:25:53"
  }, 
  {
    "objectID": "c48c044cf7fa49d477a96f6b925819877aa1fa54",
    "permalink": "/post/sip%E5%BA%94%E7%AD%94%E6%B6%88%E6%81%AF%E7%8A%B6%E6%80%81%E7%A0%81/",
    "title": "Sip应答消息状态码","content": "1. 临时应答(1XX) 100 Trying 正在处理中 180 Ringing 振铃 181 call being forwarder 呼叫正在前向 182 queue 排队 183 session progress 会话进行 2. 会话成功(2XX) 200 OK 会话成功 3. 重定向(3XX) 300 multiple 多重选择 301 moved permanently 永久移动 302 moved temporaily 临时移动 305 use proxy 用户代理 380 alternative service 替代服务 4. 请求失败(4XX) 400 bad request 错误请求 401 unauthorized 未授权 402 payment required 付费要求 403 forbidden 禁止 404 not found 未发现 405 method no allowed 方法不允许 406 not acceptable 不可接受 407 proxy authentication required 代理需要认证 408 request timeout 请求超时 410 gone 离开 413 request entity too large 请求实体太大 414 request-url too long 请求URL太长 415 unsupported media type 不支持的媒体类型 416 unsupported url scheme 不支持的URL计划 420 bad extension 不良扩展 421 extension required 需要扩展 423 interval too brief 间隔太短 480 temporarily unavailable 临时失效 481 call/transaction does not exist 呼叫/事务不存在 482 loop detected 发现环路 483 too many hops 跳数太多 484 address incomplete 地址不完整 485 ambiguous 不明朗 486 busy here 这里忙 487 request terminated 请求终止 488 not acceptable here 这里请求不可接受 491 request pending 未决请求 493 undecipherable 不可辨识 5. 服务器失败(5XX) 500 server internal error 服务器内部错误 501 not implemented 不可执行 502 bad gateway 坏网关 503 service unavailable 服务无效 504 server time-out 服务器超时 505 version not supported 版本不支持 513 message too large 消息太大 6. 全局性错误(6XX) 600 busy everywhere 全忙 603 decline 丢弃 604 does not exist anywhere 不存在 606 not acceptable 不可接受 ","date": "2023-06-27 11:14:05",
    "updated": "2023-06-27 11:14:05"
  }, 
  {
    "objectID": "cef2186c6fa9f01ec991cfac7c9c5359bd7464aa",
    "permalink": "/post/elk/",
    "title": "ELK","content": " ELK-8.14.1集群安装(使用用户密码认证) 点击访问官方下载地址： https://www.elastic.co/downloads/past-releases/elasticsearch-8-14-1\nhttps://www.elastic.co/downloads/past-releases/logstash-8-14-1\nhttps://www.elastic.co/downloads/past-releases/kibana-8-14-1\n修改es节点内核的虚拟内存管理系统相关参数 echo \u0026amp;#34;vm.swappiness=0\u0026amp;#34; \u0026amp;gt;\u0026amp;gt; /etc/sysctl.conf echo \u0026amp;#34;vm.max_map_count=655350\u0026amp;#34; \u0026amp;gt;\u0026amp;gt; /etc/sysctl.conf sysctl -p 修改es节点的用户或进程资源限制，永久生效 cat /etc/security/limits.conf|grep -v \u0026amp;#34;^#\u0026amp;#34; * soft nofile 1024000 * hard nofile 1024000 * soft nproc unlimited * hard nproc unlimited * soft core unlimited * hard core unlimited * soft memlock unlimited * hard memlock unlimited [root@node7_2 ~]# ulimit -SHn 1024000 /etc/elasticsearch/elasticsearch.yml，配置文件配置保留部分，其余的全部可以删除 path.data: /var/lib/elasticsearch path.logs: /var/log/elasticsearch http.port: 9200 http.host: 0.0.0.0 xpack.security.enabled: true xpack.security.transport.ssl.enabled: false xpack.security.http.ssl.enabled: false 配置文件/etc/elasticsearch/jvm.options设置JVM …","date": "2023-06-20 11:31:04",
    "updated": "2023-06-20 11:31:04"
  }, 
  {
    "objectID": "80b8410e64439c24ec58184e9be57d3b4c7cb767",
    "permalink": "/post/k8s%E7%A6%BB%E7%BA%BF%E9%83%A8%E7%BD%B2/",
    "title": "K8s离线部署","content": " 一、前置准备 准备三台服务器，操作系统centos7.x\n硬件配置：CPU2核、内存2GB、硬盘30GB\n确保机器间网络互通，时钟同步，所需镜像及资源包下载链接：点击下载\n规划：\n节点名称 IP 安装组件 k8s-master 192.168.14.101 docker etcd kubelet kube-proxy kube-apiserver kube-controller-manager kube-scheduler k8s-node1 192.168.14.102 docker etcd kubelet kube-proxy k8s-node2 192.168.14.103 docker etcd kubelet kube-proxy docker私有仓库 192.168.14.100 docker（服务器配置可以低点） 三台服务器初始化操作\n# 关闭防火墙 systemctl stop firewalld systemctl disable firewalld # 关闭 selinux sed -i \u0026amp;#39;s/enforcing/disabled/\u0026amp;#39; /etc/selinux/config setenforce 0 # 关闭 swap swapoff -a sed -ri \u0026amp;#39;s/.*swap.*/#\u0026amp;amp;/\u0026amp;#39; /etc/fstab # master节点添加 hosts cat \u0026amp;gt;\u0026amp;gt; /etc/hosts \u0026amp;lt;\u0026amp;lt; EOF 192.168.14.101 k8s-master 192.168.14.102 k8s-node1 192.168.14.103 k8s-node2 EOF # 将桥接的 IPv4 流量传递到 iptables 的链 cat \u0026amp;gt; /etc/sysctl.d/k8s.conf \u0026amp;lt;\u0026amp;lt; EOF net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF # 生效 sysctl -p 部署docker本地私有镜像仓库 (192.168.14.100) #将资源包里面的docker_绿色免安装版.tar.gz解压，把docker_inspkg …","date": "2023-06-17 11:37:31",
    "updated": "2023-06-17 11:37:31"
  }, 
  {
    "objectID": "79b63e33c25eff57de25ae1df13d2370a4f38616",
    "permalink": "/post/ansible%E8%87%AA%E5%8A%A8%E5%8C%96/",
    "title": "Ansible自动化","content": "命令行\n#只操作一台机器,IP后面有一个逗号,多个IP用逗号连接 ansible all -i 192.168.X.X, -m ping #返回巨量的主机变量数据 ansible all -i 192.168.X.X, -m setup #拷贝本机文件到远程客户端 ansible all -m copy -a \u0026amp;#39;src=/etc/passwd dest=/tmp/passwd\u0026amp;#39; #创建目录，如果testdir目录已经存在，则不进行任何操作 ansible all -m file -a \u0026amp;#39;path=/testdir/testdir state=directory\u0026amp;#39; #删除文件或目录 ansible all -m file -a \u0026amp;#39;path=/testdir/testdir state=absent\u0026amp;#39; #向文件追加一行内容，内容已存在就跳过 ansible all -m lineinfile -a \u0026amp;#39;dest=/tmp/123.txt line=\u0026amp;#34;test\u0026amp;#34;\u0026amp;#39; #批量telnet测试 ansible all -m shell -a \u0026amp;#39;echo \u0026amp;#34;\u0026amp;#34;|telnet 192.168.100.1 8080\u0026amp;#39; #安装包,类似执行 yum install -y httpd ansible all -m yum -a \u0026amp;#39;name=httpd state=present\u0026amp;#39; #debug模块，输出当前主机对应的变量信息 ansible all -m debug -a \u0026amp;#39;msg={{ hostvars[inventory_hostname] }}\u0026amp;#39; #支持shell特性，包括执行脚本、管道命令，script和shell模块的区别是script执行控制端的脚本，shell执行远程端的脚本 ansible all -m shell -a \u0026amp;#39;/root/test.sh\u0026amp;#39; #支持shell特性，包括执行脚本、管道命令 ansible all -m shell -a \u0026amp;#39;cat /etc/passwd | grep root\u0026amp;#39; 剧本\n缩进规范：两个空格表示一个缩进 ，不平级标题之间开头相隔两个空格 注意: …","date": "2023-06-17 11:27:50",
    "updated": "2023-06-17 11:27:50"
  }, 
  {
    "objectID": "9e2c7f975521e530201e0df2bbe5de90eaa0de2f",
    "permalink": "/post/kubernetes%E4%B9%8Bproxysql%E9%9B%86%E7%BE%A4/",
    "title": "Kubernetes之proxysql集群","content": " 1.创建configmap配置文件 proxysql-cnf.yaml apiVersion: v1 kind: Service metadata: labels: app: proxysql name: proxysqlcluster namespace: cloud2 spec: clusterIP: None ports: - name: proxysql-admin port: 6032 protocol: TCP targetPort: 6032 selector: app: proxysql sessionAffinity: None type: ClusterIP --- apiVersion: v1 kind: ConfigMap metadata: name: proxysql-cnf namespace: cloud2 data: proxysql.cnf: | datadir=\u0026amp;#34;/var/lib/proxysql\u0026amp;#34; # 配置管理账号，即 6032 端口登陆的管理员账号密码。默认账号 admin 无法远程登陆，不适用于容器环境 admin_variables= { admin_credentials=\u0026amp;#34;admin:admin;proxysql-admin:Aa123456\u0026amp;#34; mysql_ifaces=\u0026amp;#34;0.0.0.0:6032\u0026amp;#34; } #全局配置 mysql_variables= { threads=4 max_connections=2048 default_query_delay=0 default_query_timeout=36000000 have_compress=true poll_timeout=2000 interfaces=\u0026amp;#34;0.0.0.0:6033\u0026amp;#34; default_schema=\u0026amp;#34;information_schema\u0026amp;#34; stacksize=1048576 #mysql数据库版本 server_version=\u0026amp;#34;8.0.30\u0026amp;#34; connect_timeout_server=3000 #mysql中创建并授权的监控用户密码 monitor_username=\u0026amp;#34;proxysql_monitor\u0026amp;#34; …","date": "2023-06-16 11:36:24",
    "updated": "2023-06-16 11:36:24"
  }, 
  {
    "objectID": "0ca8e8beb9025c88594c63ce8d4cf4aef8985606",
    "permalink": "/post/kubernetes/",
    "title": "Kubernetes","content": " 命令收集 ########################### 集群管理 ########################### #1、#设置节点roles名(master、node) kubectl label node \u0026amp;lt;node-name\u0026amp;gt; node-role.kubernetes.io/master= kubectl label node \u0026amp;lt;node-name\u0026amp;gt; node-role.kubernetes.io/node= #2、设置节点不可调度、可调度 kubectl cordon \u0026amp;lt;node-name\u0026amp;gt; #不可调度 kubectl uncordon \u0026amp;lt;node-name\u0026amp;gt; #取消不可调度 #3、查看集群信息 kubectl cluster-info #4、查看节点信息 kubectl describe node \u0026amp;lt;node-name\u0026amp;gt; #5、查看命名空间信息 kubectl describe namespace \u0026amp;lt;namespace-name\u0026amp;gt; #6、驱逐node上已经运行的业务容器 kubectl drain --ignore-daemonsets \u0026amp;lt;node-name\u0026amp;gt; #7、给节点添加标签、删除标签 kubectl label node \u0026amp;lt;node-name\u0026amp;gt; key=value kubectl label node \u0026amp;lt;node-name\u0026amp;gt; key- #8、给节点添加污点、删除污点 kubectl taint nodes \u0026amp;lt;node-name\u0026amp;gt; key1=value1:NoSchedule kubectl taint nodes \u0026amp;lt;node-name\u0026amp;gt; key1:NoSchedule- #9、查看现有node的label kubectl get node \u0026amp;lt;node-name\u0026amp;gt; --show-labels #10、查看污点 kubectl describe nodes \u0026amp;lt;node-name\u0026amp;gt; #11、查看常驻集群内的后台程序 kubectl get daemonset -A ########################### Pod …","date": "2023-06-15 11:32:05",
    "updated": "2023-06-15 11:32:05"
  }, 
  {
    "objectID": "d58c004136a8264d892d94aed280aba39b9e8b30",
    "permalink": "/post/kubernetes%E4%B9%8Bstatefulset%E9%83%A8%E7%BD%B2etcd%E9%9B%86%E7%BE%A4/",
    "title": "Kubernetes之StatefulSet部署etcd集群","content": " 0、etcd版本镜像构建Dockerfile # wget https://github.com/etcd-io/etcd/releases/download/v3.5.7/etcd-v3.5.7-linux-amd64.tar.gz FROM ccr.ccs.tencentyun.com/zoehuawang/etcd:v3.4.13 COPY etcd-v3.5.7-linux-amd64/etcd* /usr/local/bin/ COPY ca.pem /root/ COPY etcd.pem /root/ COPY etcd-key.pem /root/ RUN chmod 777 /usr/local/bin/etcd RUN chmod 777 /usr/local/bin/etcdctl 1、在指定node打上需要的标签（pv和pod都需要） 2、创建pv和sc apiVersion: v1 kind: PersistentVolume metadata: name: apisix-etcd-pv1 spec: capacity: storage: 2Gi accessModes: - ReadWriteOnce volumeMode: Filesystem persistentVolumeReclaimPolicy: Delete storageClassName: apisix-etcd-storage local: path: /mnt/etcd nodeAffinity: required: nodeSelectorTerms: - matchExpressions: - key: apisixetcd operator: In values: - pv1 --- apiVersion: v1 kind: PersistentVolume metadata: name: apisix-etcd-pv2 spec: capacity: storage: 2Gi accessModes: - ReadWriteOnce volumeMode: Filesystem persistentVolumeReclaimPolicy: Delete storageClassName: apisix-etcd-storage local: path: …","date": "2023-06-13 11:35:16",
    "updated": "2023-06-13 11:35:16"
  }, 
  {
    "objectID": "e20b1b8a0ca6572e9bd300c1ca020194295cd6f3",
    "permalink": "/post/mgr%E5%8D%95%E4%B8%BB/",
    "title": "MGR单主","content": " 1.每个节点设置hostname，并添加/etc/hosts 2.下载 gperftools-devel 和 mysql 安装包 yum install --downloadonly --downloaddir=/root gperftools-devel https://downloads.mysql.com/archives/community 3.安装步骤 yum remove mariadb-libs-5.5.60-1.el7_5.x86_64 -y rpm -ivh mysql-community-client-plugins-8.0.36-1.el7.x86_64.rpm rpm -ivh mysql-community-common-8.0.36-1.el7.x86_64.rpm rpm -ivh mysql-community-libs-8.0.36-1.el7.x86_64.rpm rpm -ivh mysql-community-client-8.0.36-1.el7.x86_64.rpm rpm -ivh mysql-community-debuginfo-8.0.36-1.el7.x86_64.rpm rpm -ivh mysql-community-embedded-compat-8.0.36-1.el7.x86_64.rpm rpm -ivh mysql-community-icu-data-files-8.0.36-1.el7.x86_64.rpm rpm -ivh mysql-community-libs-compat-8.0.36-1.el7.x86_64.rpm rpm -ivh mysql-community-devel-8.0.36-1.el7.x86_64.rpm --force --nodeps rpm -ivh mysql-community-server-8.0.36-1.el7.x86_64.rpm --force --nodeps rpm -ivh mysql-community-server-debug-8.0.36-1.el7.x86_64.rpm --force --nodeps rpm -ivh mysql-community-test-8.0.36-1.el7.x86_64.rpm --force …","date": "2023-06-13 11:34:09",
    "updated": "2023-06-13 11:34:09"
  }, 
  {
    "objectID": "2ed6d246535362e7165638e50bac4134460a6325",
    "permalink": "/post/freeswitch/",
    "title": "Freeswitch","content": "freeswitch权威指南\nFreeSWITCH 文档\n#各配置文件作用 vars.xml | 一些经常使用变量 dialplan/default.xml | 缺省的拨号计划 directory/default/*.xml | SIP用户，每用户一个文件 sip_profiles/internal.xml | 一个SIP profile，或称做一个SIP-UA，监听在本地IP及端口5060，通常供内网用户使用 sip_profiles/externa.xml | 另外一个SIP-UA，用做外部链接，端口5080 autoload_configs/modules.conf.xml | 配置当FreeSWITCH启动时自动装载哪些模块 autoload_configs/switch.conf.xml | 主要用于配置全局参数 #批量创建用户xml放在默认路径下 （添加用户后记得修改拨号计划Local_Extension正则匹配规则，并执行reloadxml生效） /usr/local/freeswitch-1.10.6/scripts/perl/add_user --users=1020-1039 #修改sip注册默认密码，可加快拨打响应时间，改完执行reloadxml生效 sed -i \u0026amp;#39;s/default_password=1234/default_password=Aa123456/g\u0026amp;#39; /usr/local/freeswitch/conf/vars.xml #修改默认socket连接密码，改完重启或者重新加载模块(fs_cli -x \u0026amp;#34;reload mod_event_socket\u0026amp;#34;) sed -i \u0026amp;#39;s/ClueCon/NewPa55w4/g\u0026amp;#39; /usr/local/freeswitch/conf/autoload_configs/event_socket.conf.xml #修改socket连接指定使用了哪个ACL列表 通过/usr/local/freeswitch/conf/autoload_configs/event_socket.conf.xml中 \u0026amp;lt;param name=\u0026amp;#34;apply-inbound-acl\u0026amp;#34; value=\u0026amp;#34;lan\u0026amp;#34;/\u0026amp;gt;的value指定acl …","date": "2023-06-13 11:09:57",
    "updated": "2023-06-13 11:09:57"
  }, 
  {
    "objectID": "2da0566ffdae9899291b2deb366c69c96611df16",
    "permalink": "/post/kafka/",
    "title": "Kafka","content": " 使用命令 #kafka服务启动： ./kafka-server-start.sh ../config/server.properties #通过zk查看kafka集群成员： ./zkCli.sh -server localhost:2181 ls /brokers/ids #查看有哪些topic： ./kafka-topics.sh --list --zookeeper zk服务IP:2181 #创建topic： ./kafka-topics.sh --create --zookeeper zk服务IP:2181 --replication-factor 1 --partitions 1 --topic test1 #topic分区数修改： ./kafka-topics.sh --zookeeper zk服务IP:2181 -alter --partitions 4 --topic test1 #kafka生产(无key型消息)： ./kafka-console-producer.sh --broker-list kafka服务IP:9092 --topic test1 #kafka生产(有key型消息，key与value间默认使用“Tab键”进行分隔，--property key.separator=\u0026amp;#39;分隔符合\u0026amp;#39;)： ./kafka-console-producer.sh --broker-list kafka服务IP:9092 --topic test1 --property parse.key=true --property key.separator=\u0026amp;#39;@\u0026amp;#39; #kafka消费(不输出key) ./kafka-console-consumer.sh --bootstrap-server kafka服务IP:9092 --from-beginning --topic test1 #kafka消费(输出key) ./kafka-console-consumer.sh --bootstrap-server kafka服务IP:9092 --from-beginning --topic test1 --property print.key=true #删除topic：(要彻底删除必须把kafka中与当前topic相关的数据目录 …","date": "2023-06-12 11:17:49",
    "updated": "2023-06-12 11:17:49"
  }, 
  {
    "objectID": "4fa4a2d841f5174f4178d56250299856c610cfb8",
    "permalink": "/post/freeswitch-1.10.6%E7%9A%84docker%E9%95%9C%E5%83%8F%E6%9E%84%E5%BB%BA/",
    "title": "Freeswitch 1.10.6的docker镜像构建","content": "Dockerfile文件内容\nFROM ccr.ccs.tencentyun.com/zoehuawang/debian:10-slim ENV TZ=Asia/Shanghai RUN echo \u0026#34;deb http://mirrors.163.com/debian/ buster main non-free contrib\u0026#34; \u0026gt; /etc/apt/sources.list RUN echo \u0026#34;deb-src http://mirrors.163.com/debian/ buster main non-free contrib\u0026#34; \u0026gt;\u0026gt; /etc/apt/sources.list RUN echo \u0026#34;deb http://mirrors.163.com/debian-security buster/updates main\u0026#34; \u0026gt;\u0026gt; /etc/apt/sources.list RUN echo \u0026#34;deb-src http://mirrors.163.com/debian-security buster/updates main\u0026#34; \u0026gt;\u0026gt; /etc/apt/sources.list RUN echo \u0026#34;deb http://mirrors.163.com/debian/ buster-updates main non-free contrib\u0026#34; \u0026gt;\u0026gt; /etc/apt/sources.list RUN echo \u0026#34;deb-src http://mirrors.163.com/debian/ buster-updates main non-free contrib\u0026#34; \u0026gt;\u0026gt; /etc/apt/sources.list RUN apt-get update \u0026amp;\u0026amp; apt-get upgrade -y RUN apt-get install gcc g++ autoconf automake make libtool libtool-bin pkg-config \\ sngrep uuid-dev libtiff-dev libsqlite3-dev libvpx-dev libldns-dev \\ libpcre3-dev libspeex-dev libedit-dev libcurl4-openssl-dev libshout3-dev \\ libavformat-dev libswscale-dev ca-certificates \\ libspeexdsp-dev libssl-dev yasm liblua5.1-0-dev libopus-dev libmpg123-dev \\ libmp3lame-dev libsndfile1-dev git -y --no-install-recommends \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* RUN cd /usr/local/ \\ \u0026amp;\u0026amp; git clone https://gitee.com/zoewang/spandsp.git \\ \u0026amp;\u0026amp; git clone https://gitee.com/zoewang/sofia-sip.git \\ \u0026amp;\u0026amp; git clone https://gitee.com/zoewang/freeswitch.git freeswitch-1.10.6 RUN cd /usr/local/spandsp/ \\ \u0026amp;\u0026amp; ./bootstrap.sh -j \u0026amp;\u0026amp; ./configure \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install \u0026amp;\u0026amp; ldconfig RUN cd /usr/local/sofia-sip/ \\ \u0026amp;\u0026amp; ./bootstrap.sh -j \u0026amp;\u0026amp; ./configure \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install \u0026amp;\u0026amp; ldconfig COPY modules.conf /usr/local/freeswitch-1.10.6 WORKDIR /usr/local/freeswitch-1.10.6 RUN ./bootstrap.sh RUN ./configure --disable-dependency-tracking RUN make \u0026amp;\u0026amp; make install RUN rm -rf /etc/localtime \\ \u0026amp;\u0026amp; ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \\ \u0026amp;\u0026amp; echo \u0026#39;export PATH=\u0026#34;/usr/local/freeswitch/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; /root/.bashrc WORKDIR /usr/local/freeswitch ENTRYPOINT [\u0026#34;/usr/local/freeswitch/bin/freeswitch\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;-nonat\u0026#34;] modules.conf文件内容\n#applications/mod_abstraction #applications/mod_avmd applications/mod_av #applications/mod_bert #applications/mod_blacklist #applications/mod_callcenter #applications/mod_cidlookup #applications/mod_cluechoo applications/mod_commands applications/mod_conference #applications/mod_curl applications/mod_db #applications/mod_directory applications/mod_distributor applications/mod_dptools #applications/mod_easyroute #applications/mod_enum applications/mod_esf #applications/mod_esl applications/mod_expr applications/mod_fifo #applications/mod_fsk applications/mod_fsv applications/mod_hash applications/mod_httapi #applications/mod_http_cache #applications/mod_ladspa #applications/mod_lcr #applications/mod_memcache #applications/mod_mongo #applications/mod_mp4 #applications/mod_nibblebill #applications/mod_oreka #applications/mod_osp #applications/mod_prefix #applications/mod_rad_auth #applications/mod_redis #applications/mod_rss #applications/mod_sonar applications/mod_sms #applications/mod_snapshot #applications/mod_snipe_hunt #applications/mod_snom #applications/mod_soundtouch applications/mod_spandsp #applications/mod_spy #applications/mod_stress #applications/mod_translate applications/mod_valet_parking #applications/mod_vmd applications/mod_voicemail #applications/mod_voicemail_ivr #applications/mod_random #asr_tts/mod_cepstral #asr_tts/mod_flite #asr_tts/mod_pocketsphinx #asr_tts/mod_tts_commandline asr_tts/mod_unimrcp codecs/mod_amr #codecs/mod_amrwb #codecs/mod_bv #codecs/mod_b64 #codecs/mod_celt #codecs/mod_codec2 #codecs/mod_com_g729 #codecs/mod_dahdi_codec codecs/mod_g723_1 codecs/mod_g729 codecs/mod_h26x codecs/mod_vp8 #codecs/mod_ilbc #codecs/mod_isac #codecs/mod_mp4v codecs/mod_opus #codecs/mod_sangoma_codec #codecs/mod_silk #codecs/mod_siren #codecs/mod_theora dialplans/mod_dialplan_asterisk #dialplans/mod_dialplan_directory dialplans/mod_dialplan_xml #directories/mod_ldap #endpoints/mod_alsa #endpoints/mod_dingaling #endpoints/mod_gsmopen #endpoints/mod_h323 #endpoints/mod_khomp endpoints/mod_rtc endpoints/mod_verto endpoints/mod_loopback #endpoints/mod_opal #endpoints/mod_portaudio endpoints/mod_rtmp endpoints/mod_skinny #endpoints/mod_skypopen endpoints/mod_sofia #endpoints/mod_unicall #event_handlers/mod_amqp #event_handlers/mod_cdr_csv #event_handlers/mod_cdr_mongodb #event_handlers/mod_cdr_pg_csv event_handlers/mod_cdr_sqlite #event_handlers/mod_erlang_event #event_handlers/mod_event_multicast event_handlers/mod_event_socket #event_handlers/mod_event_zmq #event_handlers/mod_format_cdr #event_handlers/mod_json_cdr #event_handlers/mod_radius_cdr #event_handlers/mod_odbc_cdr #event_handlers/mod_rayo #event_handlers/mod_snmp formats/mod_local_stream formats/mod_native_file #formats/mod_portaudio_stream #formats/mod_shell_stream formats/mod_shout formats/mod_sndfile #formats/mod_ssml formats/mod_tone_stream formats/mod_png #formats/mod_vlc #languages/mod_basic #languages/mod_java languages/mod_lua #languages/mod_managed #languages/mod_perl #languages/mod_python #languages/mod_v8 #languages/mod_yaml loggers/mod_console #loggers/mod_graylog2 loggers/mod_logfile loggers/mod_syslog #say/mod_say_de say/mod_say_en #say/mod_say_es #say/mod_say_es_ar #say/mod_say_fa #say/mod_say_fr #say/mod_say_he #say/mod_say_hr #say/mod_say_hu #say/mod_say_it #say/mod_say_ja #say/mod_say_nl #say/mod_say_pl #say/mod_say_pt #say/mod_say_ru #say/mod_say_th #say/mod_say_zh #say/mod_say_sv #timers/mod_posix_timer #timers/mod_timerfd xml_int/mod_xml_cdr xml_int/mod_xml_curl #xml_int/mod_xml_ldap #xml_int/mod_xml_radius xml_int/mod_xml_rpc xml_int/mod_xml_scgi #../../libs/freetdm/mod_freetdm ## Experimental Modules (don\u0026#39;t cry if they\u0026#39;re broken) #../../contrib/mod/xml_int/mod_xml_odbc 构建命令： docker build -t freeswitch:1.10.6 .\nMakefile文件内容\n# Makefile Version 1.2.0 # 路径映射 # /usr/local/freeswitch/conf # /usr/local/freeswitch/sounds # /usr/local/freeswitch/scripts # /usr/local/freeswitch/log # /usr/local/freeswitch/recordings init: -docker rm -f fs; docker run -d --network host \\\\ --name fs freeswitch:1.10.6 copy-conf: docker cp fs:/usr/local/freeswitch/conf ./ run: -docker rm -f fs; docker run -d --network host \\\\ -v $$PWD/conf:/usr/local/freeswitch/conf \\\\ -v $$PWD/log:/usr/local/freeswitch/log \\\\ --name fs freeswitch:1.10.6 #fs_cli: #\tdocker exec -it fs /usr/local/freeswitch/bin/fs_cli ","date": "2023-06-12 11:06:57",
    "updated": "2023-06-12 11:06:57"
  }, 
  {
    "objectID": "71fa6d70b9067cd7f95504bc3f84c551c1ae784b",
    "permalink": "/post/rabbitmq%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/",
    "title": "RabbitMQ集群部署","content": " 配置hosts(3个节点) 192.168.100.1 VM_100_1_centos 192.168.100.2 VM_100_2_centos 192.168.100.3 VM_100_3_centos 安装 下载链接：点击下载\nrpm -ivh erlang-19.0.4-1.el7.centos.x86_64.rpm rabbitmq-server-3.6.12-1.el7.noarch.rpm 配置启动(3个节点都操作) vim /usr/lib/systemd/system/rabbitmq-server.service [Unit] Description=RabbitMQ broker After=syslog.target network.target [Service] Type=notify User=rabbitmq Group=rabbitmq WorkingDirectory=/var/lib/rabbitmq ExecStart=/usr/sbin/rabbitmq-server ExecStop=/usr/sbin/rabbitmqctl stop ExecStop=/bin/sh -c \u0026#34;while ps -p $MAINPID \u0026gt;/dev/null 2\u0026gt;\u0026amp;1; do sleep 1; done\u0026#34; NotifyAccess=all TimeoutStartSec=3600 LimitNOFILE=300000 [Install] WantedBy=multi-user.target systemctl daemon-reload systemctl start rabbitmq-server.service systemctl status rabbitmq-server.service 配置插件(3个节点都操作) rabbitmq-plugins enable rabbitmq_management rabbitmq-plugins enable rabbitmq_stomp rabbitmq-plugins enable rabbitmq_top 配置集群 vim /var/lib/rabbitmq/.erlang.cookie UUPJPTKFQPZPDSORCBMS #文件内容保持一致组成同一集群，文件权限400，要保证.erlang.cookie文件的所属用户及组都为rabbitmq scp /var/lib/rabbitmq/.erlang.cookie root@192.168.100.2:/var/lib/rabbitmq/ scp /var/lib/rabbitmq/.erlang.cookie root@192.168.100.3:/var/lib/rabbitmq/ vim /etc/rabbitmq/rabbitmq.config [{rabbit, [{loopback_users, []},{vm_memory_high_watermark, 0.75},{cluster_partition_handling, pause_minority}]}]. 默认情况下，RabbitMQ使用内存超过40%的时候，会发出内存警告，阻塞所有发布消息的连接，一旦警告解除（例如：服务器paging消息到硬盘或者分发消息到消费者并且确认）服务会恢复正常。默认的内存阀值是40%，注意，这并不会阻止RabbitMQ Server使用不到40%，仅仅意味着到达这个点的时候，发布者会被阻塞block，最坏的情况下，Erlang虚拟机会引起双倍的内存使用（RAM的80%），强烈建议开启操作系统的SWAP和Page files.内存达到阀值后，发布者会被阻塞，但是消费者不会被阻塞，消费者继续消费消息，当内存降低到阀值以下后，发布者继续开始发布消息。\n重启(3个节点都操作) systemctl restart rabbitmq-server.service systemctl status rabbitmq-server.service 添加组成集群（将1作为主节点，在2，3上分别执行以下命令：） rabbitmqctl stop_app rabbitmqctl reset rabbitmqctl join_cluster rabbit@VM_100_1_centos rabbitmqctl start_app rabbitmqctl cluster_status 访问其中一个节点的管理端口查看集群状态（默认用户名密码都是：guest） http://192.168.100.2:15627\n","date": "2023-06-11 11:33:00",
    "updated": "2023-06-11 11:33:00"
  }, 
  {
    "objectID": "83f58eb953ad20c135b8d735a7dbfd56cb727bf8",
    "permalink": "/post/freeswitch-1.4.26%E5%9F%BA%E6%9C%AC%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/",
    "title": "Freeswitch 1.4.26基本安装使用","content": "#下载源码包 wget \u0026lt;https://files.freeswitch.org/releases/freeswitch/freeswitch-1.4.26.tar.gz\u0026gt; #安装依赖 yum install -y autoconf automake libtool gcc-c++ ncurses-devel make zlib-devel \\\\ libjpeg-devel openssl-devel e2fsprogs-devel curl-devel pcre-devel speex-devel \\\\ sqlite-devel ldns ldns-devel libedit-devel #解压进入源码包 tar -zxf freeswitch-1.4.26.tar.gz \u0026amp;\u0026amp; cd freeswitch-1.4.26 #配置，默认路径/usr/local/freeswitch ./configure #编译安装 make \u0026amp;\u0026amp; make install #修改客户端可以远程连接配置 (密码、监听端口也是这里面修改) sed -i \u0026#39;s/127.0.0.1/0.0.0.0/g\u0026#39; /usr/local/freeswitch/conf/autoload_configs/event_socket.conf.xml #修改sip注册默认密码，可加快拨打响应时间，default_password /usr/local/freeswitch/conf/vars.xml #如果机器不支持ipv6把相关配置删除 rm -rf /usr/local/freeswitch/conf/sip_profiles/external-ipv6* /usr/local/freeswitch/conf/sip_profiles/internal-ipv6* #后台启动 freeswitch -nc -nonat #停止 /usr/local/freeswitch/bin/freeswitch -stop #登陆控制台 /usr/local/freeswitch/bin/fs_cli -P端口 -p密码 -l日志级别 #-x执行命令 /usr/local/freeswitch/bin/fs_cli -x \u0026#34;show calls as json\u0026#34; #各配置文件作用 vars.xml | 一些经常使用变量 dialplan/default.xml | 缺省的拨号计划 directory/default/*.xml | SIP用户，每用户一个文件 sip_profiles/internal.xml | 一个SIP profile，或称做一个SIP-UA，监听在本地IP及端口5060，通常供内网用户使用 sip_profiles/externa.xml | 另外一个SIP-UA，用做外部链接，端口5080 autoload_configs/modules.conf.xml | 配置当FreeSWITCH启动时自动装载哪些模块 ","date": "2023-06-11 11:08:28",
    "updated": "2023-06-11 11:08:28"
  }, 
  {
    "objectID": "c3cf57313a78caf65941b63df77b3dde485104e0",
    "permalink": "/post/python/",
    "title": "Python","content": "Python扩展包大全：https://www.lfd.uci.edu/~gohlke/pythonlibs\nMiniconda3下载地址：https://repo.anaconda.com/miniconda\npython3常用进制转换： hex(16) # 10进制转16进制 oct(8) # 10进制转8进制 bin(8) # 10进制转2进制 int(\u0026amp;#39;10\u0026amp;#39;) # 字符串转换成10进制整数 int(\u0026amp;#39;10\u0026amp;#39;,16) # 字符串转换成16进制整数 int(\u0026amp;#39;0x10\u0026amp;#39;,16) # 字符串转换成16进制整数 int(\u0026amp;#39;10\u0026amp;#39;,8) # 字符串转换成8进制整数 int(\u0026amp;#39;010\u0026amp;#39;,8) # 字符串转换成8进制整数 int(\u0026amp;#39;10\u0026amp;#39;,2) # 字符串转换成2进制整数 python时间格式 time.strftime(\u0026amp;#39;%Y-%m-%d %H:%M:%S\u0026amp;#39;,time.localtime()) # \u0026amp;#39;1900-01-01 08:00:01\u0026amp;#39; time.strftime(\u0026amp;#39;%X\u0026amp;#39;) # \u0026amp;#39;08:00:01\u0026amp;#39; datetime.datetime.now().strftime(\u0026amp;#39;%Y-%m-%d %H:%M:%S\u0026amp;#39;)\t# \u0026amp;#39;1900-01-01 08:00:01\u0026amp;#39; pip安装包临时提速方法 #在 pip install 包名 后面加上 -i + 镜像地址，这样 pip 安装时即可成倍的提速了,国内主要镜像地址如下： 清华：https://pypi.tuna.tsinghua.edu.cn/simple 阿里云：https://mirrors.aliyun.com/pypi/simple 中国科技大学: https://pypi.mirrors.ustc.edu.cn/simple 华中理工大学：http://pypi.hustunique.com 山东理工大学：http://pypi.sdutlinux.org 豆瓣：http://pypi.douban.com/simple Python中yield的用法详解 首先，如果你还没有对yield有个初步分认识，那么你先把yield看 …","date": "2023-06-09 11:23:25",
    "updated": "2023-06-09 11:23:25"
  }, 
  {
    "objectID": "83dacff04f292daa67a25f41845fcb034c1eb5e9",
    "permalink": "/post/%E6%95%B0%E6%8D%AE%E5%BA%93/",
    "title": "数据库","content": " \u0026amp;ndash;—————————Mysql—————————\u0026amp;ndash; select version(); #查看mysql版本 stop slave;set global sql_slave_skip_counter=1;start slave; #从库不同步处理，第二句表示跳过一步错误,后面的数字可变 #从库不同步处理，复制的时候忽略指定的表 stop slave ; CHANGE REPLICATION FILTER REPLICATE_WILD_IGNORE_TABLE = (\u0026amp;#39;库.表\u0026amp;#39;); start slave; #去掉忽略表 CHANGE REPLICATION FILTER REPLICATE_WILD_IGNORE_TABLE = (); #主从同步change master to语法 change master to master_host=\u0026amp;#39;192.168.1.4\u0026amp;#39;,master_user=\u0026amp;#39;slave\u0026amp;#39;,master_password=\u0026amp;#39;Aa123456\u0026amp;#39;,master_port=13306,master_log_file=\u0026amp;#39;mysql-bin.000201\u0026amp;#39;,master_log_pos=628152168; #设置MySQL为只读模式 show global variables like \u0026amp;#34;%read_only%\u0026amp;#34;; flush tables with read lock; set global read_only=1; show global variables like \u0026amp;#34;%read_only%\u0026amp;#34;; #将MySQL从只读设置为读写状态 unlock tables; set global read_only=0; select a.id,a.column,b.id,b.column from a left join b on a.id = b.id #关联查询 select CONCAT_WS(‘#’,str1,str2,…) from\t#查询结果以\u0026amp;#34;#\u0026amp;#34;号分隔 show master logs;\t#查看总共有几个binlog文件 set global expire_logs_days = …","date": "2023-06-08 11:22:21",
    "updated": "2023-06-08 11:22:21"
  }, 
  {
    "objectID": "3aeccecbaa157fd23f9402d920209fc2b301b54f",
    "permalink": "/post/keepalived%E9%AB%98%E5%8F%AF%E7%94%A8%E9%85%8D%E7%BD%AE/",
    "title": "Keepalived高可用配置","content": " yum直接安装 yum -y install keepalived 或者RPM包安装 rpm -ivh psmisc-22.20-17.el7.x86_64.rpm --force --nodeps --replacepkgs rpm -ivh libnl3-3.2.28-4.el7.x86_64.rpm --force --nodeps --replacepkgs rpm -ivh net-snmp-libs-5.7.2-49.el7_9.4.x86_64.rpm --force --nodeps --replacepkgs rpm -ivh net-snmp-agent-libs-5.7.2-49.el7_9.4.x86_64.rpm --force --nodeps --replacepkgs rpm -ivh lm_sensors-libs-3.4.0-8.20160601gitf9185e5.el7_9.1.x86_64.rpm --force --nodeps --replacepkgs rpm -ivh perl-libs-5.16.3-299.el7_9.x86_64.rpm --force --nodeps --replacepkgs rpm -ivh keepalived-1.3.5-19.el7.x86_64.rpm --force --nodeps --replacepkgs /etc/keepalived/keepalived.conf配置文件内容： ! Configuration File for keepalived global_defs { vrrp_skip_check_adv_addr } vrrp_script check_Mysqld { script \u0026#34;killall -0 mysqld\u0026#34; interval 2 fall 2 weight -20 } vrrp_instance VI_1 { state BACKUP interface ens192 virtual_router_id 66 priority 100 advert_int 1 authentication { auth_type PASS auth_pass Aa123456 } virtual_ipaddress { 192.168.7.58 } #当实例变为主服务器时，会执行指定的脚本 /etc/keepalived/notify_action.sh，并将参数 MASTER 传递给该脚本 #notify_master \u0026#34;/etc/keepalived/notify_action.sh MASTER\u0026#34; #当实例从主服务器状态切换到备用服务器状态时，会执行同样的脚本，但这次传递的参数是 BACKUP #notify_backup \u0026#34;/etc/keepalived/notify_action.sh BACKUP\u0026#34; #当检测到故障（例如，主服务器无法访问），它会执行该脚本，并将参数 FAULT 传递给脚本 #notify_fault \u0026#34;/etc/keepalived/notify_action.sh FAULT\u0026#34; #当服务停止时，会执行该脚本，并将参数 STOP 传递给脚本 #notify_stop \u0026#34;/etc/keepalived/notify_action.sh STOP\u0026#34; track_script { check_Mysqld } } 两个节点都是BACKUP，配置的priority权重一样，让他们通过脚本控制权重来竞争VIP。如果有多个节点且有相同的优先级，Keepalived会选择IP地址更高的那个节点作为主节点。 interface为网卡名称，不一样的话注意修改; 同一环境内,virtual_router_id 唯一且两个节点一致; interval 2 表示每2秒执行一次脚本; fall 2 表示连续两次执行脚本都异常才认定为异常，判断的依据是脚本返回的状态码：0为正常，非0异常; 如果script脚本执行结果非0（即执行结果异常），则优先级相应的减少20; 如果script脚本执行结果为0（即执行结果正常），则优先级相应的会还原;\n","date": "2023-06-08 11:21:16",
    "updated": "2023-06-08 11:21:16"
  }, 
  {
    "objectID": "48700a81700b051495df3ddbaf1445dabcf8b0cb",
    "permalink": "/post/docker/",
    "title": "Docker","content": "资源链接：http://www.rpmfind.net/linux/rpm2html/search.php?query=docker\ndocker inspect CONTAINER_NAME #查看容器所有信息 docker container port CONTAINER_NAME #查看容器端口映射信息 docker logs CONTAINER_NAME #查看启动日志 docker history IMAGE_NAME #查看镜像构建 docker volum COMMAND #管理数据卷 容器启动自动执行~/.bashrc #内部取得root权限(centos7) 在docker run的时候加上--privileged=true参数，然后在最后面加上/usr/sbin/init。 #指定hostname --hostname \u0026amp;lt;hostname\u0026amp;gt; #指定网络，host模式，容器将不会获得一个独立的Network，和宿主机共享网络IP和端口 --network=host #修改hosts文件 在docker run的时候加上--add-host machine:ip #修改hosts文件 或在/etc/bashrc文件末尾添加 echo \u0026amp;#34;ip hostname\u0026amp;#34; \u0026amp;gt;\u0026amp;gt; /etc/hosts #windows添加永久静态路由 route add 10.10.0.0 mask 255.255.255.0 10.0.75.2 IF 接口号 route add 172.17.0.0 mask 255.255.255.0 10.0.75.2 IF 接口号 接口号通过 route -4 print 查看，最左边一列就是接口号 #夸宿主机与容器网路互通添加路由（宿主机IP为10.1.24.*） 主机1：route add -net 172.16.12.0/16 gw 10.1.24.225 主机2：route add -net 172.16.12.0/16 gw 10.1.24.223 如果要添加为永久路由：就在在/etc/rc.local里添加 #php容器中添加pdo_mysql扩展模块 docker-php-ext-install pdo_mysql #docker删除none标签镜像 docker …","date": "2023-06-07 11:15:16",
    "updated": "2023-06-07 11:15:16"
  }, 
  {
    "objectID": "1c8023478e03a66e3bc5c020275195604fe566fe",
    "permalink": "/post/git/",
    "title": "Git","content": "#将本地仓库关联到名为\u0026#34;origin\u0026#34;的远程仓库 git remote add origin https://gitee.com/zoewang/repo.git #从名为\u0026#34;origin\u0026#34;的远程仓库中获取最新的提交信息同步到本地仓库 git fetch origin #将本地重置为服务器端的版本 git reset --hard origin/master #添加当前目录下的所有文件到暂存区 git add . #提交暂存区文件到本地仓库 git commit -m \u0026#34;[message]\u0026#34; #修改文件后不需要执行 git add 命令，直接来提交 git commit -a #将本地的分支版本上传到远程并合并 git push #强制将本地的分支版本上传到远程并合并 git push -f origin master #配置用户名 git config --global user.name \u0026#34;your name\u0026#34; #配置邮箱 git config --global user.email \u0026#34;your email\u0026#34; ","date": "2023-06-04 11:16:58",
    "updated": "2023-06-04 11:16:58"
  }, 
  {
    "objectID": "830fa7c5e1b24d11b1090fc8a61722e27d26bf68",
    "permalink": "/post/golang/",
    "title": "Golang","content": " 编译成Linux可执行文件 先设置环境：\nSET CGO_ENABLED=0\nSET GOARCH=amd64\nSET GOOS=linux\n然后运行： go build -o 编译成的文件名\nGolang的格式化输出 # 定义示例类型和变量 type Human struct { Name string } var people = Human{Name:\u0026amp;#34;zhangsan\u0026amp;#34;} 普通占位符 占位符 说明 举例 输出 %v 相应值的默认格式。 Printf(\u0026amp;#34;%v\u0026amp;#34;, people) {zhangsan}， %+v 打印结构体时，会添加字段名 Printf(\u0026amp;#34;%+v\u0026amp;#34;, people)\t{Name:zhangsan} %#v 相应值的Go语法表示 Printf(\u0026amp;#34;#v\u0026amp;#34;, people) main.Human{Name:\u0026amp;#34;zhangsan\u0026amp;#34;} %T 相应值的类型的Go语法表示 Printf(\u0026amp;#34;%T\u0026amp;#34;, people) main.Human %% 字面上的百分号，并非值的占位符 Printf(\u0026amp;#34;%%\u0026amp;#34;) % 布尔占位符 占位符 说明 举例 输出 %t true 或 false。 Printf(\u0026amp;#34;%t\u0026amp;#34;, true) true 整数占位符 占位符 说明 举例 输出 %b 二进制表示 Printf(\u0026amp;#34;%b\u0026amp;#34;, 5) 101 %c 相应Unicode码点所表示的字符 Printf(\u0026amp;#34;%c\u0026amp;#34;, 0x4E2D) 中 %d 十进制表示 Printf(\u0026amp;#34;%d\u0026amp;#34;, 0x12) 18 %o 八进制表示 Printf(\u0026amp;#34;%d\u0026amp;#34;, 10) 12 %q 单引号围绕的字符字面值，由Go语法安全地转义 Printf(\u0026amp;#34;%q\u0026amp;#34;, 0x4E2D) \u0026amp;#39;中\u0026amp;#39; %x 十六进制表示，字母形式为小写 a-f Printf(\u0026amp;#34;%x\u0026amp;#34;, 13) d %X 十六进制表示，字母形式为大写 A-F Printf(\u0026amp;#34;%x\u0026amp;#34;, 13) D %U Unicode格式：U+1234，等同于 \u0026amp;#34;U+%04X\u0026amp;#34; Printf(\u0026amp;#34;%U\u0026amp;#34;, …","date": "2023-06-02 11:26:49",
    "updated": "2023-06-02 11:26:49"
  }, 
  {
    "objectID": "557a09a05715badfe3c3fbfa91b2ada48ba9350f",
    "permalink": "/post/%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2openvpn/",
    "title": "快速部署openvpn","content": " 一键部署脚本下载: https://github.com/angristan/openvpn-install\n配置文件/etc/openvpn/server.conf补充 port 2305 proto udp dev tun user nobody group nobody persist-key persist-tun keepalive 5 120 topology subnet server 10.5.5.0 255.255.255.0 ifconfig-pool-persist ipp.txt push \u0026#34;route 172.29.77.0 255.255.255.0\u0026#34; push \u0026#34;route 172.25.209.0 255.255.255.0\u0026#34; dh none #从radius验证密码，不需要可不添加 #plugin /etc/openvpn/radiusplugin.so /etc/openvpn/radiusplugin.cnf ecdh-curve prime256v1 tls-crypt tls-crypt.key crl-verify crl.pem ca ca.crt cert server_e3IxyFUI3a4mnQXr.crt key server_e3IxyFUI3a4mnQXr.key auth SHA256 cipher AES-128-GCM ncp-ciphers AES-128-GCM tls-server tls-version-min 1.2 tls-cipher TLS-ECDHE-ECDSA-WITH-AES-128-GCM-SHA256 client-config-dir /etc/openvpn/ccd status /var/log/openvpn/status.log verb 3 reneg-sec 0 配置iptables，内部流量通过openvpn服务端转发 iptables -t nat -A POSTROUTING -s 10.5.5.0/24 -d 172.29.77.0/24 -o eth0 -j MASQUERADE 插件配置文件/etc/openvpn/radiusplugin.cnf NAS-Identifier=OpenVpn Service-Type=5 Framed-Protocol=1 NAS-Port-Type=5 NAS-IP-Address=127.0.0.1 OpenVPNConfig=/etc/openvpn/server.conf subnet=255.255.255.0 overwriteccfiles=true nonfatalaccounting=false server { # The UDP port for radius accounting. acctport=1813 # The UDP port for radius authentication. authport=1812 # The name or ip address of the radius server. name=1xx.1xx.1xx.1xx # How many times should the plugin send the if there is no response? retry=1 # How long should the plugin wait for a response? wait=3 # The shared secret. sharedsecret=Rad2023 } ","date": "2023-01-02 10:54:44",
    "updated": "2023-01-02 10:54:44"
  }, 
  {
    "objectID": "b595c5cc7da101fc4a2dfc27d1f14d29e8d4d18e",
    "permalink": "/post/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8Ffrp/",
    "title": "内网穿透frp","content": "通过访问服务端代理到客户端上，详见 https://github.com/fatedier/frp\n服务端示例，版本 v0.62.0： 配置文件 frps.toml\nbindAddr = \u0026#34;172.23.33.3\u0026#34; bindPort = 7788 auth.method = \u0026#34;token\u0026#34; auth.token = \u0026#34;wellcloudavqoub89\u0026#34; 启动服务端\n./frps -c frps.toml 客户端示例，版本 v0.62.0： 配置文件 frpc.toml\nserverAddr = \u0026#34;172.23.33.3\u0026#34; serverPort = 7788 auth.method = \u0026#34;token\u0026#34; auth.token = \u0026#34;wellcloudavqoub89\u0026#34; [[proxies]] name = \u0026#34;test-tcp\u0026#34; type = \u0026#34;tcp\u0026#34; localIP = \u0026#34;172.23.33.11\u0026#34; localPort = 22 remotePort = 6622 {{- range $_, $v := parseNumberRangePair \u0026#34;18627-18629\u0026#34; \u0026#34;18627-18629\u0026#34; }} [[proxies]] name = \u0026#34;udp-{{ $v.First }}\u0026#34; type = \u0026#34;udp\u0026#34; localIP = \u0026#34;172.23.33.11\u0026#34; localPort = {{ $v.First }} remotePort = {{ $v.Second }} {{- end }} 启动客户端\n./frpc -c frpc.toml ","date": "2022-10-11 11:02:07",
    "updated": "2022-10-11 11:02:07"
  }, 
  {
    "objectID": "208fc8658bf450010953fa4a2a60757e6c8419fd",
    "permalink": "/post/rpmbuild%E5%B0%86%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%E5%A5%BD%E7%9A%84%E8%BD%AF%E4%BB%B6%E6%89%93%E6%88%90rpm%E5%8C%85/",
    "title": "rpmbuild将编译安装好的软件打成RPM包","content": " 以zookeeper举例： 安装rpmbuild yum install rpm-build rpmdevtools 创建RPM构建目录 mkdir -p ~/rpmbuild/{BUILD,BUILDROOT,RPMS,SOURCES,SPECS,SRPMS} 将需要打包的文件和目录压缩成%{name}-%{version}.tar.gz包放到~/rpmbuild/SOURCES下（压缩成tar包的的时候要以绝对路径的方式） tar -zcf zookeeper-3.8.4.tar.gz /opt/zookeeper /usr/lib/systemd/system/zookeeper.service mv zookeeper-3.8.4.tar.gz ~/rpmbuild/SOURCES/ 创建spec文件 vim ~/rpmbuild/SPECS/zookeeper.spec Name: zookeeper Version: 3.8.4 Release: 1 Summary: 摘要信息 License: 许可证类型 Source0: %{name}-%{version}.tar.gz BuildArch: x86_64 # 描述信息 %description # 准备源代码（例如，解压源码包） %prep # 编译源代码 %build # 将编译好的文件复制到构建根目录 %install rm -rf $RPM_BUILD_ROOT mkdir -p $RPM_BUILD_ROOT/opt/zookeeper tar xfz $RPM_SOURCE_DIR/%{name}-%{version}.tar.gz -C $RPM_BUILD_ROOT/ # 定义需要包含在RPM包中的文件，并设置属性 %files %defattr(-,root,root,-) /opt/zookeeper/bin /opt/zookeeper/conf /opt/zookeeper/lib /opt/zookeeper/logs /usr/lib/systemd/system/zookeeper.service #构建完成后 %clean rm -rf $RPM_BUILD_ROOT # 在目标系统安装RPM前 %pre getent group zookeeper \u0026gt;/dev/null || groupadd --system zookeeper getent passwd zookeeper \u0026gt;/dev/null || useradd --system -M -g zookeeper -s /sbin/nologin zookeeper # 在目标系统安装RPM后 %post systemctl daemon-reload chown zookeeper. /opt/zookeeper -R # 在目标系统卸载RPM前 %preun systemctl stop zookeeper \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 systemctl disable zookeeper # 在目标系统卸载RPM后 %postun rm -rf /opt/zookeeper %changelog * Tue Jun 25 2025 - Initial release 打成rpm包命令 rpmbuild -bb --define \u0026#34;dist %{nil}\u0026#34; ~/rpmbuild/SPECS/zookeeper.spec ","date": "2022-05-05 10:29:50",
    "updated": "2022-05-05 10:29:50"
  }, 
  {
    "objectID": "92de6636bda1fba6d887b73ef775420ba3b467cc",
    "permalink": "/post/ffmpeg/",
    "title": "ffmpeg","content": " ffmpeg简单使用，可用于剪辑视频\n#参数解释： #旧版中的-acodec在新版中写法是-c:a #旧版中的-vcodec在新版中写法是-c:v #使用 copy 直接复制音频流时，需要确保 输入的编码格式与输出的格式兼容 -i \u0026amp;#34;URL\u0026amp;#34; 输入流媒体地址或源媒体文件 -c:v copy 复制视频流（不转码） -c:a copy 复制音频流（不转码） -c:v libx264 视频转码为 H.264（MP4/MKV） -c:v libx265 视频转码为 H.265（MP4/MKV） -c:a aac 音频转码为 AAC（MP4/M4A） -c:a pcm_s16le 音频转码为 PCM 16-bit（WAV） -c:a libmp3lame 音频转码为 MP3（MP3） -vn 禁用视频录制（纯音频输出） -an 禁用音频录制（纯视频输出） #下载音频媒体流（不转码） ffmpeg -i \u0026amp;#34;音频流媒体URL\u0026amp;#34; -c:a copy output.mp3 #下载音频流媒体并转成mp3 ffmpeg -i \u0026amp;#34;音频流媒体URL\u0026amp;#34; -c:a libmp3lame output.mp3 #下载视频媒体流（不转码） ffmpeg -i \u0026amp;#34;视频流媒体URL\u0026amp;#34; -c:v copy -c:a copy output.mp4 #下载视频流媒体并转码为H.264的mp4的视频 ffmpeg -i \u0026amp;#34;视频流媒体URL\u0026amp;#34; -c:v libx264 -c:a aac output.mp4 #只提取视频流媒体中的音频并转码为AAC的mp4的音频 ffmpeg -i \u0026amp;#34;视频流媒体URL\u0026amp;#34; -vn -c:a aac audio.mp4 #只提取视频流媒体中的音频并转码为PCM 16-bit的wav音频 ffmpeg -i \u0026amp;#34;视频流媒体URL\u0026amp;#34; -vn -c:a pcm_s16le audio.wav #只提取视频流媒体中的音频并保存为mp3，音频质量等级为4 ffmpeg -i \u0026amp;#34;视频流媒体URL\u0026amp;#34; -vn -c:a libmp3lame -q:a 4 output.mp3 #只提取视频流媒体中视频 ffmpeg -i \u0026amp;#34;视频流媒体URL\u0026amp;#34; -c:v …","date": "2021-07-02 11:05:49",
    "updated": "2021-07-02 11:05:49"
  }, 
  {
    "objectID": "748fcd5dffb57fcfac53f23584edd6c9cc29fff8",
    "permalink": "/post/%E9%93%B6%E8%A1%8C%E9%A1%B9%E7%9B%AE%E5%AE%9E%E7%8E%B0%E5%BE%AE%E4%BF%A1%E5%91%8A%E8%AD%A6/",
    "title": "银行项目实现微信告警","content": " 背景说明 银行项目的服务器都是处于行方的内网环境中，运维的监控告警手段只有邮件和电话；每次收到邮件又没有很好的提醒效果，而电话告警方式播报告警内容的时候不够明确，且接听麻烦。因此可以增加微信告警方式（告警内容清晰明确且收到微信也能及时提醒）。虽然内网环境的服务器不能直接通过zabbix调用微信接口发送告警,但可以利用邮件与外网联通。具体做法就是把告警邮件发送给自己的邮箱，然后利用自己服务器通过python扫描邮件，一旦发现有新的告警邮件就通过企业微信接口发送消息到微信\n准备工作 1、去企业微信官网注册用户，点此进入官方链接（注册个人的就行，不需要企业），注册完之后并登录在应用管理里面创建应用，该应用就是用于发送告警消息的，创建好应用点击进入就可以看到有API发送消息的能力。然后就可以通过企业微信API里面的发送消息接口给创建好的应用发送消息，具体调用方法请移步企业微信开放平台\n2、一个专门用于接收告警邮件的邮箱，我这里需要用的是IMAP服务，所以使用QQ邮箱。邮箱设置里面的账户需要开启POP，开启后会提供一个授权码（python脚本里面登陆邮箱的时候需要用到这个授权码），并设置收件规则把告警邮件都转移到master文件夹内\n3、准备一台能通公网的服务器，通过这个服务器登陆邮箱并发送告警消息\n脚本参考 1、调用发送应用消息接口需要接口调用凭证(access_token)，access_token有时间限制，有效期为两小时（有效期内无限制使用），过期后需要重新获取，所以把获取凭证脚本(get_token.py)添加到定时任务，每小时获取一次就可以了。\n50 * * * * python3 /home/channelsoft/get_token.py import requests import json appid = \u0026amp;#34;wwc4xxxxxxxxxx62b\u0026amp;#34; #企业corpid secret = \u0026amp;#34;mZzBuOxYQs4xxxxxxxxxxxxcAy_zM6PmhbCmFTI84\u0026amp;#34; #企业应用secret url = …","date": "2021-06-08 11:24:20",
    "updated": "2021-06-08 11:24:20"
  }, 
  {
    "objectID": "19885dfd0cbba3b5577b6cb3287769dceae3bf69",
    "permalink": "/post/linux/",
    "title": "Linux","content": "#home目录下所有文件更新时间距现在时刻大于120分钟的文件删除(-mtime -3 表示3天以内) find /home/* -mmin +120 -delete #home目录下所有文件创建时间距现在时刻大于120分钟的文件删除(-ctime -3 表示3天以内) find /home/* -cmin +120 -delete #快速查找已删除但依旧占用的文件 find /proc/*/fd -ls 2\u0026amp;gt;/dev/null | grep \u0026amp;#39;(deleted)\u0026amp;#39; tar -zcf XXX.tar.gz XXX --remove-files #打包成tar包之后删除原文件 #替换jar内文件(包内要和包外的路径对应一致，不然会说没有这个文件) jar -uvf XXX.jar 包内文件 包外文件 sort file1 file2 | uniq -u #去除两个文件重复部分 ln –s 源文件 目标文件 #软链接 ls --full-time filename #查看文件生成全部时间 ls -lR | grep \u0026amp;#34;^-\u0026amp;#34; | wc -l #查看当前目录下的文件数量（包含子目录中的文件） 注意：R，代表子目录 ls -l | grep \u0026amp;#34;^-\u0026amp;#34; | wc -l #查看当前目录下的文件数量（不包含子目录中的文件） ls -l | grep \u0026amp;#34;^d\u0026amp;#34; | wc -l #查看当前目录下的文件夹数量（不包含子目录中的目录），同上述理，如果需要查看子目录的，加上R #不解压筛选查看tar.gz包(或zgrep --binary-files=text \u0026amp;#34;Read time out\u0026amp;#34; X.tar.gz) zcat XXX.tar.gz | grep --binary-files=text \u0026amp;#34;Read time out\u0026amp;#34; #对于所有3306端口的TCP访问，一律转发到 192.168.7.51:3306 上 socat -d -d -lf /var/log/socat.log TCP4-LISTEN:3306,bind=0.0.0.0,reuseaddr,fork TCP4:192.168.7.51:3306 #screen命令用法 screen -S …","date": "2020-07-09 11:29:50",
    "updated": "2020-07-09 11:29:50"
  }]